import datetime
import assemblyai as aai
from dotenv import load_dotenv
import os
import re
import json

# Load environment variables from .env file
load_dotenv()

# Get the API key from the environment
api_key = os.getenv("ASSEMBLYAI_API_KEY")

if not api_key:
    raise ValueError("API key is not set. Please check your .env file.")

aai.settings.api_key = api_key
transcriber = aai.Transcriber()

# Function to transcribe speech
def transcribe_audio(audio_url):
    """
    Transcribes an audio file from a URL using AssemblyAI.
    """
    try:
        print("Transcribing audio...")
        transcript = transcriber.transcribe(audio_url)
        if transcript.status == aai.TranscriptStatus.error:
            print(f"Transcription failed: {transcript.error}")
            return None
        return transcript
    except Exception as e:
        print(f"Transcription error: {e}")
        return None

# Function to extract task details using LLM
def extract_task_details_llm(transcript_obj):
    """
    Extracts structured task details (task, with whom, at what time) from transcript using an LLM.
    """
    prompt = (
        "Understand the following text and extract structured information about a task. "
        "Return only a JSON object with the following fields: 'task', 'with_whom', and 'time'. "
        "Do not include any additional text or explanations.\n\n"
        f"Text: {transcript_obj.text}\n\n"
        "Response:"
    )

    try:
        print("Enhancing understanding with LLM...")
        result = transcript_obj.lemur.task(
            prompt, final_model=aai.LemurModel.claude3_5_sonnet
        )
        
        # Log raw response
        print("Raw LLM Response:", result.response)

        # Ensure response is JSON formatted
        try:
            structured_response = json.loads(result.response)
            return structured_response
        except json.JSONDecodeError:
            print("Response is not in JSON format. Parsing manually.")
            structured_response = parse_text_response(result.response)
            return structured_response
    except Exception as e:
        print("LLM processing failed:", e)
        return None

# Define the parse_text_response function
def parse_text_response(response_text):
    """
    Parses a response text to extract structured data when JSON decoding fails.
    This is a simple implementation and may need to be tailored based on your LLM's output.
    """
    try:
        # Find the start of the JSON object
        json_start = response_text.find('{')
        if json_start == -1:
            print("No JSON object found in the response.")
            return {}

        json_str = response_text[json_start:]
        # Remove any trailing characters after the JSON object
        json_end = json_str.rfind('}') + 1
        json_str = json_str[:json_end]

        data = json.loads(json_str)
        return data
    except Exception as e:
        print(f"Error parsing text response: {e}")
        return {}

# Function to generate clarifying questions
def generate_clarifying_questions(transcript_obj, task_details):
    """
    Uses the LLM to generate contextual and meaningful clarifying questions 
    based on missing task details and inferred context.
    """
    # Identify missing or ambiguous fields
    existing_fields = task_details.keys()
    prompt = (
        f"The extracted task details are incomplete or ambiguous:\n"
        f"{json.dumps(task_details, indent=2)}\n\n"
        "Please generate clarifying questions to gather more information "
        "about the task. These questions should help make the event more detailed"
        "Return the questions as a JSON array. Do not include any explanations."
    )

    try:
        print("Generating clarifying questions with LLM...")
        result = transcript_obj.lemur.task(
            prompt, final_model=aai.LemurModel.claude3_5_sonnet
        )
        print("Raw LLM Clarifying Questions Response:", result.response)

        # Parse the JSON response
        questions = json.loads(result.response)
        return questions if isinstance(questions, list) else []
    except Exception as e:
        print("Failed to generate clarifying questions:", e)
        return []

# Function to dynamically update task details
def answer_clarifying_questions(questions):
    """
    Asks the user the clarifying questions generated by the LLM.
    Dynamically updates the task_details dictionary with new fields.
    """
    answers = {}
    for question in questions:
        # Ask the user for input
        answer = input(f"{question.strip()} ").strip()

        # Dynamically infer the key from the question
        inferred_key = None
        if "time" in question.lower():
            inferred_key = "time"
        elif "where" in question.lower():
            inferred_key = "location"
        elif "participants" in question.lower() or "who" in question.lower():
            inferred_key = "participants"
        elif "purpose" in question.lower() or "agenda" in question.lower():
            inferred_key = "agenda"
        elif "duration" in question.lower() or "how long" in question.lower():
            inferred_key = "duration"

        # If a key is inferred, update the answers dictionary
        if inferred_key:
            answers[inferred_key] = answer
        else:
            # If no key is inferred, use a generic key
            answers[f"custom_field_{len(answers)+1}"] = answer

    return answers

# Function to create a polished calendar-like event
def create_calendar_event(task_details):
    """
    Constructs a clean and detailed calendar event.
    """
    task = task_details.get("task", "No task specified")
    with_whom = task_details.get("with_whom", "Not specified")
    time = task_details.get("time", "No time provided")
    location = task_details.get("location", "Not specified")
    participants = task_details.get("participants", "Not specified")
    agenda = task_details.get("agenda", "Not specified")
    duration = task_details.get("duration", "Not specified")

    # Create a detailed calendar event string
    event = (
        f"\n=== Calendar Event ===\n"
        f"Task: {task}\n"
        f"With: {with_whom}\n"
        f"Time: {time}\n"
        f"Location: {location}\n"
        f"Participants: {participants}\n"
        f"Agenda: {agenda}\n"
        f"Duration: {duration}\n"
        f"======================"
    )
    return event

# Main Function
def main(audio_url):
    # Step 1: Transcribe audio
    transcript_obj = transcribe_audio(audio_url)
    if not transcript_obj:
        print("Failed to transcribe audio.")
        return

    print(f"\nTranscript:\n{transcript_obj.text}")

    # Step 2: Extract task details using LLM
    task_details = extract_task_details_llm(transcript_obj)
    if not task_details:
        print("Failed to extract task details.")
        return

    print("\nExtracted Task Details:")
    print(task_details)

    # Step 3: Generate clarifying questions
    questions = generate_clarifying_questions(transcript_obj, task_details)
    if questions:
        print("\nClarifying Questions:")
        for question in questions:
            print(f"- {question}")

        # Step 4: Answer clarifying questions
        answers = answer_clarifying_questions(questions)
        task_details.update(answers)

    print("\nUpdated Task Details:")
    print(task_details)

    # Step 5: Create a polished calendar event
    calendar_event = create_calendar_event(task_details)
    print(calendar_event)

# Example Usage
if __name__ == "__main__":
    # List of audio files to process
    audio_files = ["audio.wav"]
    
    for audio_file in audio_files:
        print(f"\nProcessing file: {audio_file}\n{'='*30}")
        main(audio_file)
